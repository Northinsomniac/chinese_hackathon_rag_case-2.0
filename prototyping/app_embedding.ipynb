{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb39041-134e-4b57-9fe7-0bf6d1224b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:16:51.684796Z",
     "iopub.status.busy": "2024-06-14T14:16:51.683690Z",
     "iopub.status.idle": "2024-06-14T14:16:57.580067Z",
     "shell.execute_reply": "2024-06-14T14:16:57.579183Z",
     "shell.execute_reply.started": "2024-06-14T14:16:51.684754Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests==2.28.1 in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.28.1)\n",
      "Requirement already satisfied: opensearch-py in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: pdf2image in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: PyJWT in /usr/lib/python3/dist-packages (from -r requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: langchain in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.2.4)\n",
      "Requirement already satisfied: sentence_transformers in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.0.1)\n",
      "Requirement already satisfied: InstructorEmbedding in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: unstructured in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.14.5)\n",
      "Requirement already satisfied: langchain-community in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.2.4)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.20.24)\n",
      "Requirement already satisfied: fastwarc in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.14.7)\n",
      "Requirement already satisfied: langchain_huggingface in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.0.3)\n",
      "Requirement already satisfied: html2text in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2024.2.26)\n",
      "Requirement already satisfied: pyspark in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (3.5.1)\n",
      "Requirement already satisfied: spark-nlp in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (5.3.3)\n",
      "Requirement already satisfied: zhon in /home/jupyter/.local/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (2.0.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (3.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/jupyter/.local/lib/python3.10/site-packages (from requests==2.28.1->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.1->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyter/.local/lib/python3.10/site-packages (from requests==2.28.1->-r requirements.txt (line 1)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.1->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from opensearch-py->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from opensearch-py->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: Events in /home/jupyter/.local/lib/python3.10/site-packages (from opensearch-py->-r requirements.txt (line 2)) (0.5)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image->-r requirements.txt (line 3)) (9.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 5)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 5)) (2.0.19)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 5)) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 5)) (4.0.2)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.6 in /home/jupyter/.local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 5)) (0.2.6)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/jupyter/.local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/jupyter/.local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 5)) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 5)) (1.22.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 5)) (1.10.12)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 5)) (8.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /home/jupyter/.local/lib/python3.10/site-packages (from sentence_transformers->-r requirements.txt (line 6)) (4.41.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->-r requirements.txt (line 6)) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->-r requirements.txt (line 6)) (2.0.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->-r requirements.txt (line 6)) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->-r requirements.txt (line 6)) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/jupyter/.local/lib/python3.10/site-packages (from sentence_transformers->-r requirements.txt (line 6)) (0.23.3)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 8)) (4.0.0)\n",
      "Requirement already satisfied: filetype in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 8)) (0.4.27)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 8)) (4.9.3)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 8)) (4.11.2)\n",
      "Requirement already satisfied: emoji in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 8)) (2.12.1)\n",
      "Requirement already satisfied: dataclasses-json in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 8)) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 8)) (2024.4.27)\n",
      "Requirement already satisfied: langdetect in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 8)) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 8)) (3.9.3)\n",
      "Requirement already satisfied: backoff in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 8)) (4.7.1)\n",
      "Requirement already satisfied: unstructured-client in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 8)) (0.8.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 8)) (1.14.1)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.24 in /usr/local/lib/python3.10/dist-packages (from boto3->-r requirements.txt (line 10)) (1.23.24)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->-r requirements.txt (line 10)) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from boto3->-r requirements.txt (line 10)) (0.5.2)\n",
      "Requirement already satisfied: brotli in /home/jupyter/.local/lib/python3.10/site-packages (from fastwarc->-r requirements.txt (line 11)) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from fastwarc->-r requirements.txt (line 11)) (8.1.6)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home/jupyter/.local/lib/python3.10/site-packages (from langchain_huggingface->-r requirements.txt (line 12)) (0.19.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark->-r requirements.txt (line 14)) (0.10.9.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 17)) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 17)) (2022.10.31)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jupyter/.local/lib/python3.10/site-packages (from dataclasses-json->unstructured->-r requirements.txt (line 8)) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/jupyter/.local/lib/python3.10/site-packages (from dataclasses-json->unstructured->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers->-r requirements.txt (line 6)) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers->-r requirements.txt (line 6)) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jupyter/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers->-r requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/jupyter/.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.6->langchain->-r requirements.txt (line 5)) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jupyter/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 5)) (3.10.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 5)) (2.0.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 6)) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 6)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 6)) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 6)) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 6)) (16.0.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers->-r requirements.txt (line 6)) (0.4.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured->-r requirements.txt (line 8)) (2.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured-client->unstructured->-r requirements.txt (line 8)) (1.0.6)\n",
      "Requirement already satisfied: marshmallow-enum>=1.5.1 in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured-client->unstructured->-r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/jupyter/.local/lib/python3.10/site-packages (from unstructured-client->unstructured->-r requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jupyter/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.6->langchain->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 6)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 6)) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468eb14-e948-47ba-a202-75afffa12959",
   "metadata": {},
   "source": [
    "# OpenSearch connection stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8959b6b6-db93-4128-8199-5022a5d526d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:19.335986Z",
     "iopub.status.busy": "2024-06-14T14:17:19.334900Z",
     "iopub.status.idle": "2024-06-14T14:17:19.386863Z",
     "shell.execute_reply": "2024-06-14T14:17:19.386111Z",
     "shell.execute_reply.started": "2024-06-14T14:17:19.335942Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-06-14 14:17:19--  https://storage.yandexcloud.net/cloud-certs/CA.pem\n",
      "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
      "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3579 (3.5K) [application/x-x509-ca-cert]\n",
      "Saving to: ‘/home/jupyter/datasphere/project/.opensearch/root.crt’\n",
      "\n",
      "     0K ...                                                   100% 3.76G=0s\n",
      "\n",
      "2024-06-14 14:17:19 (3.76 GB/s) - ‘/home/jupyter/datasphere/project/.opensearch/root.crt’ saved [3579/3579]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /home/jupyter/datasphere/project/.opensearch && \\\n",
    "wget \"https://storage.yandexcloud.net/cloud-certs/CA.pem\" \\\n",
    "     --output-document /home/jupyter/datasphere/project/.opensearch/root.crt && \\\n",
    "chmod 0600 /home/jupyter/datasphere/project/.opensearch/root.crt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb52804e-6723-4283-866e-bea751dc9c95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:24.316945Z",
     "iopub.status.busy": "2024-06-14T14:17:24.316152Z",
     "iopub.status.idle": "2024-06-14T14:17:24.594877Z",
     "shell.execute_reply": "2024-06-14T14:17:24.594064Z",
     "shell.execute_reply.started": "2024-06-14T14:17:24.316907Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'rc1a-o2ugqo3cg4h5e5cv.mdb.yandexcloud.net', 'cluster_name': 'c9qr2lf4qo2uj2k4u669', 'cluster_uuid': 'ZW5bQO5WS0SpYrWJzYuSNw', 'version': {'distribution': 'opensearch', 'number': '2.8.0', 'build_type': 'deb', 'build_hash': '8cbab9609696cd93c45fd5f3090560648c04f5af', 'build_date': '2023-10-04T14:42:52.695597332Z', 'build_snapshot': False, 'lucene_version': '9.6.0', 'minimum_wire_compatibility_version': '7.10.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'The OpenSearch Project: https://opensearch.org/'}\n"
     ]
    }
   ],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "\n",
    "CA = '/home/jupyter/datasphere/project/.opensearch/root.crt'\n",
    "\n",
    "PASS = ''\n",
    "HOSTS = [\n",
    "  \"\"\n",
    "]\n",
    "\n",
    "conn = OpenSearch(\n",
    "  HOSTS,\n",
    "  http_auth=('', PASS),\n",
    "  use_ssl=True,\n",
    "  verify_certs=True,\n",
    "  ca_certs=CA)\n",
    "\n",
    "print(conn.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558399c5-d582-4140-94ac-1e005554a6a8",
   "metadata": {},
   "source": [
    "# Yandex GPT \n",
    "## Getting IAM Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9956f4ed-1908-432a-a306-b1a49970f7e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:26.089357Z",
     "iopub.status.busy": "2024-06-14T14:17:26.088274Z",
     "iopub.status.idle": "2024-06-14T14:17:26.122198Z",
     "shell.execute_reply": "2024-06-14T14:17:26.121458Z",
     "shell.execute_reply.started": "2024-06-14T14:17:26.089315Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import jwt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953884e5-bde1-4d2d-90b6-ad2df8c8b958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:26.608624Z",
     "iopub.status.busy": "2024-06-14T14:17:26.607484Z",
     "iopub.status.idle": "2024-06-14T14:17:26.622440Z",
     "shell.execute_reply": "2024-06-14T14:17:26.621681Z",
     "shell.execute_reply.started": "2024-06-14T14:17:26.608585Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_account_id = \"\"\n",
    "key_id = \"\"\n",
    "private_key = \"\"\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9801115-f2c8-4744-8843-87c63dd8d5f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:27.813040Z",
     "iopub.status.busy": "2024-06-14T14:17:27.812049Z",
     "iopub.status.idle": "2024-06-14T14:17:28.002676Z",
     "shell.execute_reply": "2024-06-14T14:17:28.001678Z",
     "shell.execute_reply.started": "2024-06-14T14:17:27.813001Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyJ0eXAiOiJKV1QiLCJhbGciOiJQUzI1NiIsImtpZCI6ImFqZTlsMjVoZTZtZXJjOG4ybzhnIn0.eyJhdWQiOiJodHRwczovL2lhbS5hcGkuY2xvdWQueWFuZGV4Lm5ldC9pYW0vdjEvdG9rZW5zIiwiaXNzIjoiYWplZzV2bzg0aGwzbnU1YTZvOTgiLCJpYXQiOjE3MTgzNzQ2NDcsImV4cCI6MTcxODM3ODI0N30.t9wlN1jjlcVitc_q7h1uUGWkE6-H1QPZXsCZf61Fkh_y3phMC-YOmh9ombfr3DoKQRiuYUP203vZJT05oJ7L23ba4JrnI24lKdUcNOK5raGkdzp-Eel0nUiFaS0T2UqcMk-G3WOaci6fg4e9s0FAINvqSLBusR8SnJKyywK3QnR7mErMiDn5Z9q-Tm_6XUrS9IHnNspxG3pDWKye873hh6DDIXg3UmeFQqRV_pCj8npUEyD06LKahghwepV3avcmbz4reUwVx7pixzIJneGTxsJVFTX052JP6V4e9APLL7sEhLtWV3fWo501HuVHqtj2-2FtmJ8R8vqClXFji4BGrg\n"
     ]
    }
   ],
   "source": [
    "# Получаем IAM-токен\n",
    "\n",
    "now = int(time.time())\n",
    "payload = {\n",
    "        'aud': 'https://iam.api.cloud.yandex.net/iam/v1/tokens',\n",
    "        'iss': service_account_id,\n",
    "        'iat': now,\n",
    "        'exp': now + 3600\n",
    "      }\n",
    "\n",
    "\n",
    "# Формирование JWT.\n",
    "encoded_token = jwt.encode(\n",
    "    payload,\n",
    "    private_key,\n",
    "    algorithm='PS256',\n",
    "    headers={'kid': key_id}\n",
    "  )\n",
    "\n",
    "\n",
    "#Запись ключа в файл\n",
    "with open('jwt_token.txt', 'w') as j:\n",
    "   j.write(encoded_token) \n",
    "   \n",
    "# Вывод в консоль\n",
    "print(encoded_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17ad58-c7c6-4f22-a8ad-d0ed8aef1ad4",
   "metadata": {},
   "source": [
    "# Data Pipeline Started Here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354b08ec-691f-46af-bab2-725de29acad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:29.277701Z",
     "iopub.status.busy": "2024-06-14T14:17:29.276758Z",
     "iopub.status.idle": "2024-06-14T14:17:29.840058Z",
     "shell.execute_reply": "2024-06-14T14:17:29.839122Z",
     "shell.execute_reply.started": "2024-06-14T14:17:29.277658Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import LLMChain\n",
    "from YaGPT import YandexGPTEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a89fc36-cd7e-4eca-b984-f8139399e7ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:29.842575Z",
     "iopub.status.busy": "2024-06-14T14:17:29.841682Z",
     "iopub.status.idle": "2024-06-14T14:17:29.859903Z",
     "shell.execute_reply": "2024-06-14T14:17:29.858891Z",
     "shell.execute_reply.started": "2024-06-14T14:17:29.842543Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_dir = \"china-warc-archieves/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab5978-fb8a-48fd-a881-d082409e3431",
   "metadata": {},
   "source": [
    "# Load Data warc.gz files first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e0f2ea4-9706-42c2-ba17-4ac610ebeec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:30.586472Z",
     "iopub.status.busy": "2024-06-14T14:17:30.585411Z",
     "iopub.status.idle": "2024-06-14T14:17:30.771240Z",
     "shell.execute_reply": "2024-06-14T14:17:30.770380Z",
     "shell.execute_reply.started": "2024-06-14T14:17:30.586428Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.client import Config\n",
    "from pathlib import Path\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de74ffee-9643-42dc-bac3-77e367d70910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:30.915033Z",
     "iopub.status.busy": "2024-06-14T14:17:30.913907Z",
     "iopub.status.idle": "2024-06-14T14:17:31.010184Z",
     "shell.execute_reply": "2024-06-14T14:17:31.009228Z",
     "shell.execute_reply.started": "2024-06-14T14:17:30.914992Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ключи доступа к бакету\n",
    "access_id = \"\"\n",
    "access_secret = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c9f94a-f805-4054-aba0-7c69f2f3912c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:32.799809Z",
     "iopub.status.busy": "2024-06-14T14:17:32.798558Z",
     "iopub.status.idle": "2024-06-14T14:17:32.877681Z",
     "shell.execute_reply": "2024-06-14T14:17:32.876863Z",
     "shell.execute_reply.started": "2024-06-14T14:17:32.799765Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "\n",
    "s3 = session.client(\n",
    "    service_name='s3',\n",
    "    endpoint_url='https://storage.yandexcloud.net',\n",
    "    aws_access_key_id=access_id,\n",
    "    aws_secret_access_key=access_secret,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35dbd3f5-b176-459b-a08d-3591563b5745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:33.162746Z",
     "iopub.status.busy": "2024-06-14T14:17:33.161926Z",
     "iopub.status.idle": "2024-06-14T14:17:33.300050Z",
     "shell.execute_reply": "2024-06-14T14:17:33.299129Z",
     "shell.execute_reply.started": "2024-06-14T14:17:33.162705Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finance.people.com.cn-2023-04.warc.gz', 'inews.hket.com-2023-06.warc.gz', 'news.ltn.com.tw-2022-04.warc.gz', 'news.mingpao.com-2023-06.warc.gz', 'orientaldaily.on.cc-2023-03.warc.gz', 'www.zaobao.com.sg-2016-12.warc.gz']\n"
     ]
    }
   ],
   "source": [
    "# Specify the bucket name and prefix if needed\n",
    "bucket_name = 'china-warc-archieves'\n",
    "prefix = ''\n",
    "\n",
    "def list_files(bucket_name, prefix, s3_client):\n",
    "    for key in s3.list_objects(Bucket=bucket_name)['Contents']:\n",
    "        if key['Key'].endswith('.warc.gz'):\n",
    "            yield key['Key']\n",
    "        continue\n",
    "\n",
    "files = list(list_files(bucket_name, prefix, s3))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a0f62-5519-46d9-a657-de74ef44c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your Yandex Disk OAuth token\n",
    "OAUTH_TOKEN = 'YOUR_OAUTH_TOKEN'\n",
    "\n",
    "# Yandex Disk API endpoint\n",
    "YANDEX_DISK_API_URL = 'https://cloud-api.yandex.net/v1/disk/resources'\n",
    "\n",
    "# Specify the directory and OAuth token\n",
    "directory_path = 'disk:/china-warc-archieves'\n",
    "headers = {'Authorization': f'OAuth {OAUTH_TOKEN}'}\n",
    "\n",
    "def list_files(directory_path, headers):\n",
    "    params = {'path': directory_path}\n",
    "    response = requests.get(YANDEX_DISK_API_URL, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    items = response.json()['_embedded']['items']\n",
    "\n",
    "    for item in items:\n",
    "        if item['type'] == 'file' and item['name'].endswith('.warc.gz'):\n",
    "            yield item['path']\n",
    "\n",
    "# List and print .warc.gz files\n",
    "files = list(list_files(directory_path, headers))\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a28a9-2b5f-4673-9a6a-d9aeeb3c6fee",
   "metadata": {},
   "source": [
    "## Find csv file with already parsed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef6cf28b-d20f-430f-b20a-5639452dd202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:17:34.872423Z",
     "iopub.status.busy": "2024-06-14T14:17:34.871328Z",
     "iopub.status.idle": "2024-06-14T14:17:34.909998Z",
     "shell.execute_reply": "2024-06-14T14:17:34.909172Z",
     "shell.execute_reply.started": "2024-06-14T14:17:34.872385Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some struggle with processed files: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['finance.people.com.cn-2023-04.warc.gz',\n",
       " 'inews.hket.com-2023-06.warc.gz',\n",
       " 'news.ltn.com.tw-2022-04.warc.gz',\n",
       " 'news.mingpao.com-2023-06.warc.gz',\n",
       " 'orientaldaily.on.cc-2023-03.warc.gz',\n",
       " 'www.zaobao.com.sg-2016-12.warc.gz']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find pandas csv file with archieves we already compleated\n",
    "\n",
    "def try_to_find_progress_file(bucket, key = 'processed_files.csv'):\n",
    "    processed_df = None\n",
    "    try:\n",
    "        get_processed_file = s3.get_object(Bucket=bucket, Key = key)\n",
    "        processed_df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "        processed_files = set(processed_df['filename'])\n",
    "    except Exception as ex:\n",
    "        print(f\"Some struggle with processed files: {ex}\")\n",
    "        processed_files = set()\n",
    "    return processed_files\n",
    "\n",
    "processed_files = try_to_find_progress_file(bucket_name)\n",
    "\n",
    "# leave only newly uploaded files\n",
    "new_files = list(map(str, filter(lambda path: path not in processed_files, files)))\n",
    "\n",
    "new_files    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cdcf25-5029-42bd-ae46-c9e6d4f46e68",
   "metadata": {},
   "source": [
    "# Archives Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79cfd433-3cd1-498c-98f8-06ec88775068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:38:01.961027Z",
     "iopub.status.busy": "2024-06-14T14:38:01.960061Z",
     "iopub.status.idle": "2024-06-14T14:38:01.989991Z",
     "shell.execute_reply": "2024-06-14T14:38:01.989114Z",
     "shell.execute_reply.started": "2024-06-14T14:38:01.960986Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import gzip\n",
    "import chardet\n",
    "\n",
    "from fastwarc.warc import ArchiveIterator, WarcRecordType\n",
    "from fastwarc.stream_io import GZipStream, FileStream\n",
    "\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d241417-cba1-4054-8966-7663777c4091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:38:02.295080Z",
     "iopub.status.busy": "2024-06-14T14:38:02.293878Z",
     "iopub.status.idle": "2024-06-14T14:38:04.354896Z",
     "shell.execute_reply": "2024-06-14T14:38:04.354088Z",
     "shell.execute_reply.started": "2024-06-14T14:38:02.295035Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model_name='DMetaSoul/sbert-chinese-general-v2'\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0f315c3-4ba4-448e-a832-d2a9eb0f4af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:38:04.357542Z",
     "iopub.status.busy": "2024-06-14T14:38:04.356401Z",
     "iopub.status.idle": "2024-06-14T14:38:04.372028Z",
     "shell.execute_reply": "2024-06-14T14:38:04.371150Z",
     "shell.execute_reply.started": "2024-06-14T14:38:04.357505Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def encode_raw_content(encoding, raw_content):\n",
    "    encoding = encoding if encoding else chardet.detect(raw_content)['encoding']\n",
    "    html_content = raw_content.decode(encoding if encoding else 'utf-8', errors='ignore')\\\n",
    "    .encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')\n",
    "    return html_content\n",
    "\n",
    "\n",
    "def retrieve_main_text_info(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    paragraphs = \" \".join([p.get_text() for p in soup.find_all('p')])\n",
    "    titles = \" \".join([t.get_text() for t in soup.find_all(['title', 'h1', 'h2'])])\n",
    "    return paragraphs.strip(), titles.strip()\n",
    "\n",
    "\n",
    "def extract_html_from_warc(warc_file_path):\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=warc_file_path)\n",
    "    server_stream = response\n",
    "    archieve_stream = GZipStream(io.BytesIO(server_stream['Body'].read()))\n",
    "    \n",
    "    for record in ArchiveIterator(archieve_stream):\n",
    "        if not record.headers.get('Content-Type') == 'application/http; msgtype=response' and \\\n",
    "              not 'text/html' in record.http_headers.get('Content-Type', ''):\n",
    "            continue\n",
    "        payload = record.reader.read()\n",
    "        \n",
    "        html_content = encode_raw_content(record.http_charset, payload)\n",
    "        year, month = record.record_date.year, record.record_date.month\n",
    "        content, title = retrieve_main_text_info(html_content)\n",
    "        yield Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    'url': record.headers.get('WARC-Target-URI'),\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'title' : title\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4b816f2-7382-471f-9e68-7d108320bd75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:41:35.677416Z",
     "iopub.status.busy": "2024-06-14T14:41:35.676313Z",
     "iopub.status.idle": "2024-06-14T14:43:12.764132Z",
     "shell.execute_reply": "2024-06-14T14:43:12.763306Z",
     "shell.execute_reply.started": "2024-06-14T14:41:35.677375Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing finance.people.com.cn-2023-04.warc.gz...\n",
      "Processed 780 HTML documents\n",
      "page_content='2023年全民数字素养与技能提升月活动启动经济科技人民网 2023年全民数字素养与技能提升月活动启动新华社福州4月27日电记者王思北董建国以数字赋能 全民共享为主题2023年全民数字素养与技能提升月活动27日在福州举行的第六届数字中国建设峰会开幕式上启动 提升月活动由中央网信办中央党校国家行政学院教育部科技部工业和信息化部民政部人力资源社会保障部农业农村部国家卫生健康委退役军人事务部国务院国资委全国总工会全国妇联中国科协中国残联共同主办以满足人民日益增长的美好生活需要和促进人的全面发展为目标推广数字技术应用丰富教育学习资源加强能力提升培训弘扬向善网络文化加快构建全民数字素养与技能发展培育体系促进数字化发展成果更好支撑经济社会发展和民生福祉增进' metadata={'url': 'http://finance.people.com.cn/n1/2023/0427/c1004-32675164.html', 'year': 2023, 'month': 4, 'title': '2023年全民数字素养与技能提升月活动启动--经济・科技--人民网   2023年全民数字素养与技能提升月活动启动'}\n",
      "page_content='据悉提升月活动将组织举办数字素养与技能专家巡讲活动提升全民数字素养与技能主题论坛数字教育培训资源优化共享活动数字素养校园行数字科技成果路演活动数字经济与实体经济融合发展行动数字技能社区科普服务数字职业推介会农民手机应用技能常态化培训智慧助老公益活动提升退役军人数字素养与技能专项行动国有企业数字化转型行动计划全国职工数字化应用技术技能大赛巾帼好网民女性公开课活动数字素养与技能科普活动残疾人数字化职业能力提升行动等系列主题活动 全国各省自治区直辖市和新疆生产建设兵团有关部门将同期举办本地区2023年全民数字素养与技能提升月活动 分享让更多人看到 人民日报社概况 关于人民网 报社招聘 招聘英才 广告服务 合作加盟 供稿服务 数据服务 网站声明 网站律师 信息保护 联系我们 人民日报违法和不良信息举报电话01065363263 举报邮箱jubaopeoplecn 人民网服务邮箱kfpeoplecn 违法和不良信息举报电话01065363636 举报邮箱rmwjubaopeoplecn 互联网新闻信息服务许可证10120170001 增值电信业务经营许可证B120060139' metadata={'url': 'http://finance.people.com.cn/n1/2023/0427/c1004-32675164.html', 'year': 2023, 'month': 4, 'title': '2023年全民数字素养与技能提升月活动启动--经济・科技--人民网   2023年全民数字素养与技能提升月活动启动'}\n",
      "page_content='广播电视节目制作经营许可证广媒字第172号 信息网络传播视听节目许可证0104065 网络文化经营许可证 京网文202054941075号 网络出版服务许可证京字121号 京ICP证000006号 京公网安备11000002000008号 人 民 网 版 权 未 书 面 授 权 禁 止 使 Copyright 19972023 by wwwpeoplecomcn all rights reserved' metadata={'url': 'http://finance.people.com.cn/n1/2023/0427/c1004-32675164.html', 'year': 2023, 'month': 4, 'title': '2023年全民数字素养与技能提升月活动启动--经济・科技--人民网   2023年全民数字素养与技能提升月活动启动'}\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the text cleaning function\n",
    "def clean_text(text, stopwords_cn):\n",
    "    # Remove unwanted characters and normalize spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    words = word_tokenize(text)\n",
    "    cleaned_words = [word for word in words if word not in stopwords_cn]\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def process_documents(docs_transformed, text_splitter, stopwords_cn):\n",
    "    # Clean the text in the documents\n",
    "    cleaned_docs = [\n",
    "        Document(\n",
    "            page_content=clean_text(doc.page_content, stopwords_cn),\n",
    "            metadata=doc.metadata\n",
    "        )\n",
    "        for doc in docs_transformed\n",
    "    ]\n",
    "\n",
    "    # Split the cleaned documents into chunks\n",
    "    chunked_documents = text_splitter.split_documents(cleaned_docs)\n",
    "    return chunked_documents\n",
    "\n",
    "def process_warc_files(file_paths, embeddings_model, opensearch_url, http_auth, use_ssl, verify_certs, ca_certs, batch_size=10):\n",
    "    html2text_transformer = Html2TextTransformer()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=512, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"]\n",
    "    )\n",
    "\n",
    "    # NLTK stopwords for Chinese\n",
    "    stopwords_cn = set(stopwords.words('chinese'))\n",
    "\n",
    "    # Initialize OpenSearch client\n",
    "    # docsearch = OpenSearchVectorSearch.from_documents(\n",
    "    #     [],\n",
    "    #     embeddings_model,\n",
    "    #     opensearch_url=opensearch_url,\n",
    "    #     http_auth=http_auth,\n",
    "    #     use_ssl=use_ssl,\n",
    "    #     verify_certs=verify_certs,\n",
    "    #     ca_certs=ca_certs,\n",
    "    #     engine='faiss'\n",
    "    # )\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            print(f\"Processing {file_path}...\")\n",
    "            html_documents = list(extract_html_from_warc(file_path))\n",
    "            print(f\"Processed {len(html_documents)} HTML documents\")\n",
    "            \n",
    "            docs_transformed = html2text_transformer.transform_documents(html_documents)\n",
    "\n",
    "            # Batch processing\n",
    "            for i in range(0, len(docs_transformed), batch_size):\n",
    "                batch = docs_transformed[i:i + batch_size]\n",
    "                futures.append(executor.submit(process_documents, batch, text_splitter, stopwords_cn))\n",
    "            \n",
    "        for future in futures:\n",
    "            chunked_documents = future.result()\n",
    "            print(chunked_documents[-1])\n",
    "            # docsearch.add_documents(chunked_documents)\n",
    "\n",
    "process_warc_files(\n",
    "    new_files,\n",
    "    embeddings_model=embeddings_model,\n",
    "    opensearch_url=HOSTS[0],\n",
    "    http_auth=(\"admin\", PASS),\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    ca_certs=CA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589190f0-e6c6-477e-b0ee-3b8e038abd06",
   "metadata": {},
   "source": [
    "# Add vectors to OpenSearch database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b9f64-d0c4-4a7b-8102-a81f02ce7abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"在天都举行的深空探索国际会议讨论了什么？\"\n",
    "docs = docsearch.similarity_search(query, k=2)\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3801cb16-f56e-4571-911c-b7c657d810b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c9112d-d4f3-44e0-980c-1e3dfe9162c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
